{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics - Assignment 2  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written (text) solution provide your answer in Markdown in appropriate cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to use the print() function. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### About the Assignment\n",
    "\n",
    "- Assignment 2 extends Assignment 1 on credit card applications. \n",
    "\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME_TOTAL   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day(0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application= pd.read_csv('application_record.csv')\n",
    "df_credit= pd.read_csv('credit_record.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_application: 438557\n",
      "Number of rows in df_credit: 1048575\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in df_application: {len(df_application)}\")\n",
    "print(f\"Number of rows in df_credit: {len(df_credit)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 438,557 rows in df_application and 1,048,575 rows in df_credit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438510"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45985"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 438510 unique bank clients in df_application and 45985 unique bank clients in df_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777710</th>\n",
       "      <td>5150337</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-9188</td>\n",
       "      <td>-1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777711</th>\n",
       "      <td>5150337</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-9188</td>\n",
       "      <td>-1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777712</th>\n",
       "      <td>5150337</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-9188</td>\n",
       "      <td>-1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777713</th>\n",
       "      <td>5150337</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-9188</td>\n",
       "      <td>-1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777714</th>\n",
       "      <td>5150337</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-9188</td>\n",
       "      <td>-1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777715 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0       5008804           M            Y               Y             0   \n",
       "1       5008804           M            Y               Y             0   \n",
       "2       5008804           M            Y               Y             0   \n",
       "3       5008804           M            Y               Y             0   \n",
       "4       5008804           M            Y               Y             0   \n",
       "...         ...         ...          ...             ...           ...   \n",
       "777710  5150337           M            N               Y             0   \n",
       "777711  5150337           M            N               Y             0   \n",
       "777712  5150337           M            N               Y             0   \n",
       "777713  5150337           M            N               Y             0   \n",
       "777714  5150337           M            N               Y             0   \n",
       "\n",
       "        AMT_INCOME_TOTAL NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
       "0               427500.0          Working               Higher education   \n",
       "1               427500.0          Working               Higher education   \n",
       "2               427500.0          Working               Higher education   \n",
       "3               427500.0          Working               Higher education   \n",
       "4               427500.0          Working               Higher education   \n",
       "...                  ...              ...                            ...   \n",
       "777710          112500.0          Working  Secondary / secondary special   \n",
       "777711          112500.0          Working  Secondary / secondary special   \n",
       "777712          112500.0          Working  Secondary / secondary special   \n",
       "777713          112500.0          Working  Secondary / secondary special   \n",
       "777714          112500.0          Working  Secondary / secondary special   \n",
       "\n",
       "          NAME_FAMILY_STATUS NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0             Civil marriage  Rented apartment      -12005          -4542   \n",
       "1             Civil marriage  Rented apartment      -12005          -4542   \n",
       "2             Civil marriage  Rented apartment      -12005          -4542   \n",
       "3             Civil marriage  Rented apartment      -12005          -4542   \n",
       "4             Civil marriage  Rented apartment      -12005          -4542   \n",
       "...                      ...               ...         ...            ...   \n",
       "777710  Single / not married  Rented apartment       -9188          -1193   \n",
       "777711  Single / not married  Rented apartment       -9188          -1193   \n",
       "777712  Single / not married  Rented apartment       -9188          -1193   \n",
       "777713  Single / not married  Rented apartment       -9188          -1193   \n",
       "777714  Single / not married  Rented apartment       -9188          -1193   \n",
       "\n",
       "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
       "0                1                1           0           0             NaN   \n",
       "1                1                1           0           0             NaN   \n",
       "2                1                1           0           0             NaN   \n",
       "3                1                1           0           0             NaN   \n",
       "4                1                1           0           0             NaN   \n",
       "...            ...              ...         ...         ...             ...   \n",
       "777710           1                0           0           0        Laborers   \n",
       "777711           1                0           0           0        Laborers   \n",
       "777712           1                0           0           0        Laborers   \n",
       "777713           1                0           0           0        Laborers   \n",
       "777714           1                0           0           0        Laborers   \n",
       "\n",
       "        CNT_FAM_MEMBERS  MONTHS_BALANCE STATUS  \n",
       "0                     2               0      C  \n",
       "1                     2              -1      C  \n",
       "2                     2              -2      C  \n",
       "3                     2              -3      C  \n",
       "4                     2              -4      C  \n",
       "...                 ...             ...    ...  \n",
       "777710                1              -9      0  \n",
       "777711                1             -10      2  \n",
       "777712                1             -11      1  \n",
       "777713                1             -12      0  \n",
       "777714                1             -13      0  \n",
       "\n",
       "[777715 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df_application, df_credit, on='ID', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36457"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 777715 rows and 36457 unique clients in df. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How are multiple rows for each ID in df different?**\n",
    "\n",
    "In the merged DataFrame (`df`), multiple rows for each ID are different because each ID can have multiple credit records associated with it. Each row in the `df_credit` DataFrame represents a different credit record for a client, while the `df_application` DataFrame contains the application information for each client. When merged, the resulting DataFrame will have multiple rows for each client ID, where each row combines the client's application information with one of their credit records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "2. Create a new numpy array named `list_of_defaults` containing *unique* `ID` numbers for the clients who have `STATUS` = 1 in any of the last 12 months in the dataset. (2 marks) \n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` are in `list_of_defaults`, keeping only one row for each `ID` (i.e. eliminate rows with duplicate `ID`s while keeping the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (Hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "5. Increase `df_final` to a total of 4,000 rows by adding rows from `df` with unique `ID`s (nonduplicated `ID`s) which are not in `list_of_defaults`. To do this start adding the rows from the beginning of `df`. (Hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. How many clients with  overdue payments of more than 29 days and how many clients with less than 29 days overdue payments are there in `df_final`? Answer using both print() function and in Markdown text.(1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STATUS'] = df['STATUS'].map({'C': 0, 'X': 0, '0': 0, '1': 1, '2': 1, '3': 1, '4': 1, '5': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_12_months = df['MONTHS_BALANCE'].max() - 12\n",
    "list_of_defaults = df[(df['MONTHS_BALANCE'] >= last_12_months) & (df['STATUS'] == 1)]['ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[df['ID'].isin(list_of_defaults)].drop_duplicates(subset='ID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_final: 1833\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in df_final: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Number of rows in df_final: 1833"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['y'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_rows = df[~df['ID'].isin(list_of_defaults)].drop_duplicates(subset='ID', keep='first').head(4000 - len(df_final))\n",
    "df_final = pd.concat([df_final, additional_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/glsx5ls50qqbbbhkvwpkhdnc0000gn/T/ipykernel_3304/1979685076.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['y'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_final['y'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=['STATUS', 'MONTHS_BALANCE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients with overdue payments of more than 29 days: 1833.0\n",
      "Clients with less than 29 days overdue payments: 2167.0\n"
     ]
    }
   ],
   "source": [
    "overdue_29_days = df_final['y'].sum()\n",
    "not_overdue_29_days = len(df_final) - overdue_29_days\n",
    "print(f\"Clients with overdue payments of more than 29 days: {overdue_29_days}\")\n",
    "print(f\"Clients with less than 29 days overdue payments: {not_overdue_29_days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,833 people with overdue payments of more than 29 days and 2167 people with overdue payments of less than 29 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "- Delete `ID` column from `df_final` (1 marks)\n",
    "- Of the remaining variables in `df_final` and assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable, how many variable are of numeric and nominal types? Provide lists of all numeric and nominal variables. (6)\n",
    "- Using an appropriate function find and comment on the missing values in `df_final`, i.e. how many variables and how many observations? (3 marks)   \n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric variables: ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'y']\n",
      "Nominal variables: ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n"
     ]
    }
   ],
   "source": [
    "numeric_vars = df_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "nominal_vars = df_final.select_dtypes(include=[object]).columns.tolist()\n",
    "nominal_vars.remove('NAME_EDUCATION_TYPE')\n",
    "\n",
    "print(f\"Numeric variables: {numeric_vars}\")\n",
    "print(f\"Nominal variables: {nominal_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 variables of numeric type and 7 of nominal type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables with missing values: 1\n",
      "Number of missing observations: 1167\n"
     ]
    }
   ],
   "source": [
    "missing_values = df_final.isnull().sum()\n",
    "num_missing_vars = missing_values[missing_values > 0].count()\n",
    "num_missing_observations = missing_values[missing_values > 0].sum()\n",
    "\n",
    "print(f\"Number of variables with missing values: {num_missing_vars}\")\n",
    "print(f\"Number of missing observations: {num_missing_observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of variables with missing values is 1 and the number of missing onservations is 1,167. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "- Use an appropriate `pandas` function to impute missing values in `df_final` (10 marks)\n",
    "    - Be careful when deciding which method to use to replace missing observations \n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "- Briefly explain what you have done and why. (5 marks)\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_values = {var: df_final[var].median() for var in numeric_vars}\n",
    "impute_values.update({var: df_final[var].mode()[0] for var in nominal_vars})\n",
    "df_final.fillna(value=impute_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables with missing values after imputation: 0\n",
      "Number of missing observations after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "missing_values_after = df_final.isnull().sum()\n",
    "num_missing_vars_after = missing_values_after[missing_values_after > 0].count()\n",
    "num_missing_observations_after = missing_values_after[missing_values_after > 0].sum()\n",
    "\n",
    "print(f\"Number of variables with missing values after imputation: {num_missing_vars_after}\")\n",
    "print(f\"Number of missing observations after imputation: {num_missing_observations_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection of methods is based on best practices for handling missing data. These methods maintain the integrity and distribution of the dataset, ensuring the imputed values are representative of the original data. By applying these methods, the impact of missing data is minimised on the analysis and maintains the overall strucutre.\n",
    "\n",
    "**Numeric Variables**\n",
    "\n",
    "Median is used for numeric variables to impute missing values. The median is used particularly when dealing with skewed data or outliers. This method ensures the imputed values do not overly influence the distribution of the data. \n",
    "\n",
    "**Nominal Variables**\n",
    "\n",
    "For nominal variables, the method mode was used as it was the most appropriate to impute for categorial data, preserving the distribution of the categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_type_mapping = {\n",
    "    'Lower secondary': 1,\n",
    "    'Secondary / secondary special': 2,\n",
    "    'Incomplete higher': 3,\n",
    "    'Higher education': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].replace(education_type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_vars = df_final.select_dtypes(include=[object]).columns.tolist()\n",
    "df_final = pd.get_dummies(df_final, columns=nominal_vars, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "- Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "- Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (4000,)\n",
      "Shape of X: (4000, 46)\n"
     ]
    }
   ],
   "source": [
    "y = df_final['y'].astype(int).values\n",
    "X = df_final.drop(columns=['y']).values\n",
    "\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"Shape of X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "- Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 70% train and 30% test datasets (2.5 marks) \n",
    "    - Set random_state to 7 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "- Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (2800, 46)\n",
      "Shape of X_test: (1200, 46)\n",
      "Shape of y_train: (2800,)\n",
      "Shape of y_test: (1200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=7, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Support Vector Classifier and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "- Train a Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `linear` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- Train another Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- What can you say about the presence of nonlinearities in the dataset? (4 marks)\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel - Training Accuracy: 0.5867857142857142\n",
      "Linear Kernel - Test Accuracy: 0.5658333333333333\n"
     ]
    }
   ],
   "source": [
    "svc_linear = SVC(kernel='linear', random_state=7)\n",
    "svc_linear.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy_linear = accuracy_score(y_train, svc_linear.predict(X_train))\n",
    "test_accuracy_linear = accuracy_score(y_test, svc_linear.predict(X_test))\n",
    "\n",
    "print(f\"Linear Kernel - Training Accuracy: {train_accuracy_linear}\")\n",
    "print(f\"Linear Kernel - Test Accuracy: {test_accuracy_linear}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel - Training Accuracy: 0.7760714285714285\n",
      "RBF Kernel - Test Accuracy: 0.6958333333333333\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf', random_state=7)\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy_rbf = accuracy_score(y_train, svc_rbf.predict(X_train))\n",
    "test_accuracy_rbf = accuracy_score(y_test, svc_rbf.predict(X_test))\n",
    "\n",
    "print(f\"RBF Kernel - Training Accuracy: {train_accuracy_rbf}\")\n",
    "print(f\"RBF Kernel - Test Accuracy: {test_accuracy_rbf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Output\n",
    "\n",
    "#### RBF Kernel Performance\n",
    "- **Training Accuracy:** 77.6%\n",
    "- **Test Accuracy:** 69.58%\n",
    "\n",
    "#### Linear Kernel Performance\n",
    "- **Training Accuracy:** 58.68%\n",
    "- **Test Accuracy:** 56.58%\n",
    "\n",
    "The RBF's better performance on both the training and test sets suggests that the model can generalise well, capturing the essential patterns in the data without overfitting excessively.  The higher accuracy with the RBF kernel performance indicates the presence of nonlinear relationships within the dataset. These nonlinearities are effectively captured by the RBF kernel, leading to better performance. \n",
    "\n",
    "The linear kernel's poor performance highlights its limitations in capturing complex patterns. The dataset likely includes interactions and relationships between features that are inherently nonlinear, which the linear kernel fails to model. \n",
    "\n",
    "#### Conclusion\n",
    "The performance gap between the RBF kernel and the linear kernel suggests the presence of significant nonlinearities in the dataset. The RBF kernel's ability to capture these nonlinear relationships leads to higher accuracies, demonstrating the importance of using more flexible model to adaquately represent the underlying structure of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 10**\n",
    "\n",
    "- Extract 2 linear principal components from the standardised features using an appropriate `sklearn` library (5 marks)\n",
    "- Train a Support Vector Classifier on the computed principal components (5 marks) \n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "- What can you say about the ability of the 2 principal components to compress the information contained in the features matrix `X`, and why? (5 marks)     \n",
    "\n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=7)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pca = SVC(kernel='rbf', random_state=7)\n",
    "svc_pca.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on PCA components: 0.58\n",
      "Test Accuracy on PCA components: 0.5733333333333334\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_pca = accuracy_score(y_train, svc_pca.predict(X_train_pca))\n",
    "test_accuracy_pca = accuracy_score(y_test, svc_pca.predict(X_test_pca))\n",
    "\n",
    "print(f\"Training Accuracy on PCA components: {train_accuracy_pca}\")\n",
    "print(f\"Test Accuracy on PCA components: {test_accuracy_pca}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio of the 2 principal components: [0.08755806 0.05809968]\n",
      "Total explained variance by the 2 principal components: 0.14565774481327776\n",
      "The 2 principal components do not capture sufficient information from the features matrix X.\n"
     ]
    }
   ],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio of the 2 principal components: {explained_variance_ratio}\")\n",
    "print(f\"Total explained variance by the 2 principal components: {explained_variance_ratio.sum()}\")\n",
    "\n",
    "if explained_variance_ratio.sum() < 0.90:\n",
    "    print(\"The 2 principal components do not capture sufficient information from the features matrix X.\")\n",
    "else:\n",
    "    print(\"The 2 principal components capture a significant amount of information from the features matrix X.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance ratio displays the proportion of the dataset's variance that each principal component captures. In this case:\n",
    "- **First Principle Component:** 8.76% of the variance\n",
    "- **Second Principle Component:** 5.81% of the variance\n",
    "- **Total Explained Variance:** 14.57%\n",
    "\n",
    "#### Analysis Output\n",
    "The two principle components together capture only 14.57% of the total variance in the dataset. This low percentage means that a significant amount (85.43%) of the variance in the original data is not represented by these two components. \n",
    "\n",
    "The goal of principal component analysis (PCA) is to reduce the dimensionality of the data while retaining as much information (variance) as possible. With only 14.57% of the variance retained, the two principal components fail to adequately compress the information contained in the features matrix X. \n",
    "\n",
    "The accuracies of the SVM classifier (58% training accuracy and 57.33% test accuracy) using the two principal components further suggest that these components do not capture enough information to perform well in a predictive model. This inadequate compression leads to a loss of crucial information that impacts the classifier's ability to distinguish between different classes effectively. \n",
    "\n",
    "#### Conclusion\n",
    "The ability of the two principal components to compress the information contained in the features matrix X is limited. They capture only 14.57% of the variance, indicating that a significant portion of the original data's information is lost. This loss of information is reflected in the performance of the Support Vector Classifier trained on these components. To achieve better compression and retain more meaningful information, it would be necessary to use a higher number of principal components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
